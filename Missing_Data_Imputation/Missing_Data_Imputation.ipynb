{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is created in order to learn basic approaches to handle with missing values. \n",
    "The source is: https://www.kaggle.com/residentmario/simple-techniques-for-missing-data-imputation/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Style</th>\n",
       "      <th>StyleID</th>\n",
       "      <th>Size(L)</th>\n",
       "      <th>OG</th>\n",
       "      <th>FG</th>\n",
       "      <th>ABV</th>\n",
       "      <th>IBU</th>\n",
       "      <th>Color</th>\n",
       "      <th>BoilSize</th>\n",
       "      <th>BoilTime</th>\n",
       "      <th>BoilGravity</th>\n",
       "      <th>Efficiency</th>\n",
       "      <th>MashThickness</th>\n",
       "      <th>SugarScale</th>\n",
       "      <th>BrewMethod</th>\n",
       "      <th>PitchRate</th>\n",
       "      <th>PrimaryTemp</th>\n",
       "      <th>PrimingMethod</th>\n",
       "      <th>PrimingAmount</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanilla Cream Ale</td>\n",
       "      <td>/homebrew/recipe/view/1633/vanilla-cream-ale</td>\n",
       "      <td>Cream Ale</td>\n",
       "      <td>45</td>\n",
       "      <td>21.77</td>\n",
       "      <td>1.055</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.48</td>\n",
       "      <td>17.65</td>\n",
       "      <td>4.83</td>\n",
       "      <td>28.39</td>\n",
       "      <td>75</td>\n",
       "      <td>1.038</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.78</td>\n",
       "      <td>corn sugar</td>\n",
       "      <td>4.5 oz</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southern Tier Pumking clone</td>\n",
       "      <td>/homebrew/recipe/view/16367/southern-tier-pumk...</td>\n",
       "      <td>Holiday/Winter Special Spiced Beer</td>\n",
       "      <td>85</td>\n",
       "      <td>20.82</td>\n",
       "      <td>1.083</td>\n",
       "      <td>1.021</td>\n",
       "      <td>8.16</td>\n",
       "      <td>60.65</td>\n",
       "      <td>15.64</td>\n",
       "      <td>24.61</td>\n",
       "      <td>60</td>\n",
       "      <td>1.070</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zombie Dust Clone - EXTRACT</td>\n",
       "      <td>/homebrew/recipe/view/5920/zombie-dust-clone-e...</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>7</td>\n",
       "      <td>18.93</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1.018</td>\n",
       "      <td>5.91</td>\n",
       "      <td>59.25</td>\n",
       "      <td>8.98</td>\n",
       "      <td>22.71</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>extract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zombie Dust Clone - ALL GRAIN</td>\n",
       "      <td>/homebrew/recipe/view/5916/zombie-dust-clone-a...</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>7</td>\n",
       "      <td>22.71</td>\n",
       "      <td>1.061</td>\n",
       "      <td>1.017</td>\n",
       "      <td>5.80</td>\n",
       "      <td>54.48</td>\n",
       "      <td>8.50</td>\n",
       "      <td>26.50</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bakke Brygg Belgisk Blonde 50 l</td>\n",
       "      <td>/homebrew/recipe/view/89534/bakke-brygg-belgis...</td>\n",
       "      <td>Belgian Blond Ale</td>\n",
       "      <td>20</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.010</td>\n",
       "      <td>6.48</td>\n",
       "      <td>17.84</td>\n",
       "      <td>4.57</td>\n",
       "      <td>60.00</td>\n",
       "      <td>90</td>\n",
       "      <td>1.050</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.00</td>\n",
       "      <td>Sukkerlake</td>\n",
       "      <td>6-7 g sukker/l</td>\n",
       "      <td>18325.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "BeerID                                    \n",
       "1                     Vanilla Cream Ale   \n",
       "2           Southern Tier Pumking clone   \n",
       "3           Zombie Dust Clone - EXTRACT   \n",
       "4         Zombie Dust Clone - ALL GRAIN   \n",
       "5       Bakke Brygg Belgisk Blonde 50 l   \n",
       "\n",
       "                                                      URL  \\\n",
       "BeerID                                                      \n",
       "1            /homebrew/recipe/view/1633/vanilla-cream-ale   \n",
       "2       /homebrew/recipe/view/16367/southern-tier-pumk...   \n",
       "3       /homebrew/recipe/view/5920/zombie-dust-clone-e...   \n",
       "4       /homebrew/recipe/view/5916/zombie-dust-clone-a...   \n",
       "5       /homebrew/recipe/view/89534/bakke-brygg-belgis...   \n",
       "\n",
       "                                     Style  StyleID  Size(L)     OG     FG  \\\n",
       "BeerID                                                                       \n",
       "1                                Cream Ale       45    21.77  1.055  1.013   \n",
       "2       Holiday/Winter Special Spiced Beer       85    20.82  1.083  1.021   \n",
       "3                             American IPA        7    18.93  1.063  1.018   \n",
       "4                             American IPA        7    22.71  1.061  1.017   \n",
       "5                        Belgian Blond Ale       20    50.00  1.060  1.010   \n",
       "\n",
       "         ABV    IBU  Color  BoilSize  BoilTime  BoilGravity  Efficiency  \\\n",
       "BeerID                                                                    \n",
       "1       5.48  17.65   4.83     28.39        75        1.038        70.0   \n",
       "2       8.16  60.65  15.64     24.61        60        1.070        70.0   \n",
       "3       5.91  59.25   8.98     22.71        60          NaN        70.0   \n",
       "4       5.80  54.48   8.50     26.50        60          NaN        70.0   \n",
       "5       6.48  17.84   4.57     60.00        90        1.050        72.0   \n",
       "\n",
       "        MashThickness        SugarScale BrewMethod  PitchRate  PrimaryTemp  \\\n",
       "BeerID                                                                       \n",
       "1                 NaN  Specific Gravity  All Grain        NaN        17.78   \n",
       "2                 NaN  Specific Gravity  All Grain        NaN          NaN   \n",
       "3                 NaN  Specific Gravity    extract        NaN          NaN   \n",
       "4                 NaN  Specific Gravity  All Grain        NaN          NaN   \n",
       "5                 NaN  Specific Gravity  All Grain        NaN        19.00   \n",
       "\n",
       "       PrimingMethod   PrimingAmount   UserId  \n",
       "BeerID                                         \n",
       "1         corn sugar          4.5 oz    116.0  \n",
       "2                NaN             NaN    955.0  \n",
       "3                NaN             NaN      NaN  \n",
       "4                NaN             NaN      NaN  \n",
       "5         Sukkerlake  6-7 g sukker/l  18325.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_columns', None)\n",
    "df = pd.read_csv(\"../Missing_Data_Imputation/data/recipeData.csv\", encoding='latin-1').set_index(\"BeerID\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73861, 22)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                 1\n",
       "URL                  0\n",
       "Style              596\n",
       "StyleID              0\n",
       "Size(L)              0\n",
       "OG                   0\n",
       "FG                   0\n",
       "ABV                  0\n",
       "IBU                  0\n",
       "Color                0\n",
       "BoilSize             0\n",
       "BoilTime             0\n",
       "BoilGravity       2990\n",
       "Efficiency           0\n",
       "MashThickness    29864\n",
       "SugarScale           0\n",
       "BrewMethod           0\n",
       "PitchRate        39252\n",
       "PrimaryTemp      22662\n",
       "PrimingMethod    67095\n",
       "PrimingAmount    69087\n",
       "UserId           50490\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a lot of missing data. Some features have more than 50 and 80 percent of all values missed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data missing at random and not at random\n",
    "\n",
    "Most machine learning algorithms (kNN is a notable exception) cannot deal with this problem intrinsically, as they are designed for complete data. Something needs to be done with the missing data values.\n",
    "\n",
    "There are two broad classes of missing data: data missing at random, and data missing not at random. When considering what to do with our data we must keep this in mind. The typology of the missing data strongly informs how best to approach dealing with it; or rather it's safer to say that if the data is missing not completely at random, you are going to need domain expertise to understand what to do with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple approaches\n",
    "\n",
    "A number of simple approaches exist. For basic use cases, these are often enough.\n",
    "\n",
    "#### Dropping rows with null values\n",
    "\n",
    "The easiest and quickest approach to a missing data problem is dropping the offending entries. This is an acceptable solution if we are confident that the missing data in the dataset is missing at random, and if the number of data points we have access to is sufficiently high that dropping some of them will not cause us to lose generalizability in the models we build (to determine whether or not this is case, use a learning curve).\n",
    "\n",
    "**Dropping data missing not at random is dangerous. It will result in significant bias in your model in cases where data being absent corresponds with some real-world phenomenon**. Because this requires domain knowledge, usually the only way to determine if this is a problem is through manual inspection. Dropping too much data is also dangerous. It can create significant bias by depriving your algorithms of space. This is especially true of classifiers sensitive to the curse of dimensionality. For example, for this beer dataset we might not want to simply blindly drop everything, as this would result in very few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73861, 757)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only 1% of the data remains\n",
    "\n",
    "len(df), len(df.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain types of datasets will suffer from \"almost complete\" columns—e.g. columns which are missing values in a relatively small number of cases. In these cases dropping the offending records is usually fine, with the level of how OK it is depending on how close to complete the column is. This is convenient because it removes that column from the list of things you need to deal with before you can start learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping features with high nullity\n",
    "\n",
    "A feature that has a high number of empty values is unlikely to be very useful for prediction. It can often be safely dropped. For example in the beer dataset I would drop `PrimingMethod` and `PrimingAmount`; and consider dropping a couple of others as well.\n",
    "\n",
    "Dropping rare features simplifies your model, but obviously gives you fewer features to work with. Before dropping features outright, consider subsetting the part of the dataset that this value is available for and checking its feature importance when it is used to train a model in this subset. If in doing so you disover that the variable is important in the subset it is defined, consider making an effort to retain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[1], df.drop(['PrimingMethod', 'PrimingAmount'], axis='columns').shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean or median or other summary statistic substitution\n",
    "\n",
    "The remainder of the techniques available are imputation methods, as opposed to data-dropping methods. The simplest imputation method is replacing missing values with the **mean** or **median** values of the dataset at large, or some similar summary statistic. This has the advantage of being the simplest possible approach, and one that doesn't introduce any undue bias into the dataset.\n",
    "\n",
    "But: \n",
    "\n",
    "[However] with missing values that are not strictly random, especially in the presence of a great inequality in the number of missing values for the different variables, **the mean substitution method may lead to inconsistent bias**. Furthermore, this approach adds no new information (more variability of the data) but only increases the sample size and leads to an underestimate of the errors. Thus, mean substitution is not generally accepted.\n",
    "\n",
    "From: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3668100/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `mean` and `median` do not introduce any undue bias (which is actually quite debatable following to what is written just above) into the dataset but in the same time do not increase a variance of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29864, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We saw that 'MashThickness' feature has around 40% of values missing\n",
    "\n",
    "df['MashThickness'].isnull().sum() , df['MashThickness'].fillna(df['MashThickness'].mean()).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.127235233993227, 2.1272352339932263)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean is slightly changes after imputation\n",
    "\n",
    "df['MashThickness'].mean(), df['MashThickness'].fillna(df['MashThickness'].mean()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model imputation\n",
    "\n",
    "Here's a fun trick. To prepare a dataset for machine learning we need to fix missing values, and we can fix missing values by applying machine learning to that dataset! If we consider a column with missing data as our target variable, and existing columns with complete data as our predictor variables, then we may construct a machine learning model using complete records as our train and test datasets and the records with incomplete data as our generalization target. This is a fully scoped-out machine learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Style</th>\n",
       "      <th>StyleID</th>\n",
       "      <th>Size(L)</th>\n",
       "      <th>OG</th>\n",
       "      <th>FG</th>\n",
       "      <th>ABV</th>\n",
       "      <th>IBU</th>\n",
       "      <th>Color</th>\n",
       "      <th>BoilSize</th>\n",
       "      <th>BoilTime</th>\n",
       "      <th>BoilGravity</th>\n",
       "      <th>Efficiency</th>\n",
       "      <th>MashThickness</th>\n",
       "      <th>SugarScale</th>\n",
       "      <th>BrewMethod</th>\n",
       "      <th>PitchRate</th>\n",
       "      <th>PrimaryTemp</th>\n",
       "      <th>PrimingMethod</th>\n",
       "      <th>PrimingAmount</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanilla Cream Ale</td>\n",
       "      <td>/homebrew/recipe/view/1633/vanilla-cream-ale</td>\n",
       "      <td>Cream Ale</td>\n",
       "      <td>45</td>\n",
       "      <td>21.77</td>\n",
       "      <td>1.055</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.48</td>\n",
       "      <td>17.65</td>\n",
       "      <td>4.83</td>\n",
       "      <td>28.39</td>\n",
       "      <td>75</td>\n",
       "      <td>1.038</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.78</td>\n",
       "      <td>corn sugar</td>\n",
       "      <td>4.5 oz</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southern Tier Pumking clone</td>\n",
       "      <td>/homebrew/recipe/view/16367/southern-tier-pumk...</td>\n",
       "      <td>Holiday/Winter Special Spiced Beer</td>\n",
       "      <td>85</td>\n",
       "      <td>20.82</td>\n",
       "      <td>1.083</td>\n",
       "      <td>1.021</td>\n",
       "      <td>8.16</td>\n",
       "      <td>60.65</td>\n",
       "      <td>15.64</td>\n",
       "      <td>24.61</td>\n",
       "      <td>60</td>\n",
       "      <td>1.070</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zombie Dust Clone - EXTRACT</td>\n",
       "      <td>/homebrew/recipe/view/5920/zombie-dust-clone-e...</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>7</td>\n",
       "      <td>18.93</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1.018</td>\n",
       "      <td>5.91</td>\n",
       "      <td>59.25</td>\n",
       "      <td>8.98</td>\n",
       "      <td>22.71</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>extract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zombie Dust Clone - ALL GRAIN</td>\n",
       "      <td>/homebrew/recipe/view/5916/zombie-dust-clone-a...</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>7</td>\n",
       "      <td>22.71</td>\n",
       "      <td>1.061</td>\n",
       "      <td>1.017</td>\n",
       "      <td>5.80</td>\n",
       "      <td>54.48</td>\n",
       "      <td>8.50</td>\n",
       "      <td>26.50</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bakke Brygg Belgisk Blonde 50 l</td>\n",
       "      <td>/homebrew/recipe/view/89534/bakke-brygg-belgis...</td>\n",
       "      <td>Belgian Blond Ale</td>\n",
       "      <td>20</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.010</td>\n",
       "      <td>6.48</td>\n",
       "      <td>17.84</td>\n",
       "      <td>4.57</td>\n",
       "      <td>60.00</td>\n",
       "      <td>90</td>\n",
       "      <td>1.050</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specific Gravity</td>\n",
       "      <td>All Grain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.00</td>\n",
       "      <td>Sukkerlake</td>\n",
       "      <td>6-7 g sukker/l</td>\n",
       "      <td>18325.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "BeerID                                    \n",
       "1                     Vanilla Cream Ale   \n",
       "2           Southern Tier Pumking clone   \n",
       "3           Zombie Dust Clone - EXTRACT   \n",
       "4         Zombie Dust Clone - ALL GRAIN   \n",
       "5       Bakke Brygg Belgisk Blonde 50 l   \n",
       "\n",
       "                                                      URL  \\\n",
       "BeerID                                                      \n",
       "1            /homebrew/recipe/view/1633/vanilla-cream-ale   \n",
       "2       /homebrew/recipe/view/16367/southern-tier-pumk...   \n",
       "3       /homebrew/recipe/view/5920/zombie-dust-clone-e...   \n",
       "4       /homebrew/recipe/view/5916/zombie-dust-clone-a...   \n",
       "5       /homebrew/recipe/view/89534/bakke-brygg-belgis...   \n",
       "\n",
       "                                     Style  StyleID  Size(L)     OG     FG  \\\n",
       "BeerID                                                                       \n",
       "1                                Cream Ale       45    21.77  1.055  1.013   \n",
       "2       Holiday/Winter Special Spiced Beer       85    20.82  1.083  1.021   \n",
       "3                             American IPA        7    18.93  1.063  1.018   \n",
       "4                             American IPA        7    22.71  1.061  1.017   \n",
       "5                        Belgian Blond Ale       20    50.00  1.060  1.010   \n",
       "\n",
       "         ABV    IBU  Color  BoilSize  BoilTime  BoilGravity  Efficiency  \\\n",
       "BeerID                                                                    \n",
       "1       5.48  17.65   4.83     28.39        75        1.038        70.0   \n",
       "2       8.16  60.65  15.64     24.61        60        1.070        70.0   \n",
       "3       5.91  59.25   8.98     22.71        60          NaN        70.0   \n",
       "4       5.80  54.48   8.50     26.50        60          NaN        70.0   \n",
       "5       6.48  17.84   4.57     60.00        90        1.050        72.0   \n",
       "\n",
       "        MashThickness        SugarScale BrewMethod  PitchRate  PrimaryTemp  \\\n",
       "BeerID                                                                       \n",
       "1                 NaN  Specific Gravity  All Grain        NaN        17.78   \n",
       "2                 NaN  Specific Gravity  All Grain        NaN          NaN   \n",
       "3                 NaN  Specific Gravity    extract        NaN          NaN   \n",
       "4                 NaN  Specific Gravity  All Grain        NaN          NaN   \n",
       "5                 NaN  Specific Gravity  All Grain        NaN        19.00   \n",
       "\n",
       "       PrimingMethod   PrimingAmount   UserId  \n",
       "BeerID                                         \n",
       "1         corn sugar          4.5 oz    116.0  \n",
       "2                NaN             NaN    955.0  \n",
       "3                NaN             NaN      NaN  \n",
       "4                NaN             NaN      NaN  \n",
       "5         Sukkerlake  6-7 g sukker/l  18325.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the data for applying ML to it.\n",
    "# Define those Beer styles which amount of non-NaN samples is bigger than (len(df) / 100)\n",
    "\n",
    "popular_beer_styles = (pd.get_dummies(df['Style']).sum(axis='rows') > (len(df) / 100)).where(lambda v: v).dropna().index.values\n",
    "len(popular_beer_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .pipe when chaining together functions that expect Series, DataFrames or GroupBy objects. Instead of writing\n",
    "\n",
    "f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
    "\n",
    "- You can write\n",
    "\n",
    "(df.pipe(h)\n",
    "\n",
    "...    .pipe(g, arg1=a)\n",
    "\n",
    "...    .pipe(f, arg2=b, arg3=c)\n",
    "\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size(L)</th>\n",
       "      <th>OG</th>\n",
       "      <th>FG</th>\n",
       "      <th>ABV</th>\n",
       "      <th>IBU</th>\n",
       "      <th>Color</th>\n",
       "      <th>BoilSize</th>\n",
       "      <th>BoilTime</th>\n",
       "      <th>BoilGravity</th>\n",
       "      <th>Efficiency</th>\n",
       "      <th>MashThickness</th>\n",
       "      <th>BrewMethod_All Grain</th>\n",
       "      <th>BrewMethod_BIAB</th>\n",
       "      <th>BrewMethod_Partial Mash</th>\n",
       "      <th>BrewMethod_extract</th>\n",
       "      <th>SugarScale_Plato</th>\n",
       "      <th>SugarScale_Specific Gravity</th>\n",
       "      <th>Style_American Amber Ale</th>\n",
       "      <th>Style_American Brown Ale</th>\n",
       "      <th>Style_American IPA</th>\n",
       "      <th>Style_American Light Lager</th>\n",
       "      <th>Style_American Pale Ale</th>\n",
       "      <th>Style_American Porter</th>\n",
       "      <th>Style_American Stout</th>\n",
       "      <th>Style_Blonde Ale</th>\n",
       "      <th>Style_California Common Beer</th>\n",
       "      <th>Style_Cream Ale</th>\n",
       "      <th>Style_Double IPA</th>\n",
       "      <th>Style_English IPA</th>\n",
       "      <th>Style_Imperial IPA</th>\n",
       "      <th>Style_Irish Red Ale</th>\n",
       "      <th>Style_Kölsch</th>\n",
       "      <th>Style_Oatmeal Stout</th>\n",
       "      <th>Style_Other</th>\n",
       "      <th>Style_Robust Porter</th>\n",
       "      <th>Style_Russian Imperial Stout</th>\n",
       "      <th>Style_Saison</th>\n",
       "      <th>Style_Sweet Stout</th>\n",
       "      <th>Style_Weissbier</th>\n",
       "      <th>Style_Weizen/Weissbier</th>\n",
       "      <th>Style_Witbier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.77</td>\n",
       "      <td>1.055</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.48</td>\n",
       "      <td>17.65</td>\n",
       "      <td>4.83</td>\n",
       "      <td>28.39</td>\n",
       "      <td>75</td>\n",
       "      <td>1.038</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.82</td>\n",
       "      <td>1.083</td>\n",
       "      <td>1.021</td>\n",
       "      <td>8.16</td>\n",
       "      <td>60.65</td>\n",
       "      <td>15.64</td>\n",
       "      <td>24.61</td>\n",
       "      <td>60</td>\n",
       "      <td>1.070</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.00</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.010</td>\n",
       "      <td>6.48</td>\n",
       "      <td>17.84</td>\n",
       "      <td>4.57</td>\n",
       "      <td>60.00</td>\n",
       "      <td>90</td>\n",
       "      <td>1.050</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.61</td>\n",
       "      <td>1.055</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.58</td>\n",
       "      <td>40.12</td>\n",
       "      <td>8.00</td>\n",
       "      <td>29.34</td>\n",
       "      <td>70</td>\n",
       "      <td>1.047</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.82</td>\n",
       "      <td>1.054</td>\n",
       "      <td>1.014</td>\n",
       "      <td>5.36</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5.94</td>\n",
       "      <td>28.39</td>\n",
       "      <td>75</td>\n",
       "      <td>1.040</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Size(L)     OG     FG   ABV    IBU  Color  BoilSize  BoilTime  \\\n",
       "BeerID                                                                  \n",
       "1         21.77  1.055  1.013  5.48  17.65   4.83     28.39        75   \n",
       "2         20.82  1.083  1.021  8.16  60.65  15.64     24.61        60   \n",
       "5         50.00  1.060  1.010  6.48  17.84   4.57     60.00        90   \n",
       "6         24.61  1.055  1.013  5.58  40.12   8.00     29.34        70   \n",
       "8         20.82  1.054  1.014  5.36  19.97   5.94     28.39        75   \n",
       "\n",
       "        BoilGravity  Efficiency  MashThickness  BrewMethod_All Grain  \\\n",
       "BeerID                                                                 \n",
       "1             1.038        70.0            NaN                     1   \n",
       "2             1.070        70.0            NaN                     1   \n",
       "5             1.050        72.0            NaN                     1   \n",
       "6             1.047        79.0            NaN                     1   \n",
       "8             1.040        70.0            1.4                     1   \n",
       "\n",
       "        BrewMethod_BIAB  BrewMethod_Partial Mash  BrewMethod_extract  \\\n",
       "BeerID                                                                 \n",
       "1                     0                        0                   0   \n",
       "2                     0                        0                   0   \n",
       "5                     0                        0                   0   \n",
       "6                     0                        0                   0   \n",
       "8                     0                        0                   0   \n",
       "\n",
       "        SugarScale_Plato  SugarScale_Specific Gravity  \\\n",
       "BeerID                                                  \n",
       "1                      0                            1   \n",
       "2                      0                            1   \n",
       "5                      0                            1   \n",
       "6                      0                            1   \n",
       "8                      0                            1   \n",
       "\n",
       "        Style_American Amber Ale  Style_American Brown Ale  \\\n",
       "BeerID                                                       \n",
       "1                              0                         0   \n",
       "2                              0                         0   \n",
       "5                              0                         0   \n",
       "6                              0                         0   \n",
       "8                              0                         0   \n",
       "\n",
       "        Style_American IPA  Style_American Light Lager  \\\n",
       "BeerID                                                   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "5                        0                           0   \n",
       "6                        0                           0   \n",
       "8                        0                           0   \n",
       "\n",
       "        Style_American Pale Ale  Style_American Porter  Style_American Stout  \\\n",
       "BeerID                                                                         \n",
       "1                             0                      0                     0   \n",
       "2                             0                      0                     0   \n",
       "5                             0                      0                     0   \n",
       "6                             1                      0                     0   \n",
       "8                             0                      0                     0   \n",
       "\n",
       "        Style_Blonde Ale  Style_California Common Beer  Style_Cream Ale  \\\n",
       "BeerID                                                                    \n",
       "1                      0                             0                1   \n",
       "2                      0                             0                0   \n",
       "5                      0                             0                0   \n",
       "6                      0                             0                0   \n",
       "8                      0                             0                1   \n",
       "\n",
       "        Style_Double IPA  Style_English IPA  Style_Imperial IPA  \\\n",
       "BeerID                                                            \n",
       "1                      0                  0                   0   \n",
       "2                      0                  0                   0   \n",
       "5                      0                  0                   0   \n",
       "6                      0                  0                   0   \n",
       "8                      0                  0                   0   \n",
       "\n",
       "        Style_Irish Red Ale  Style_Kölsch  Style_Oatmeal Stout  Style_Other  \\\n",
       "BeerID                                                                        \n",
       "1                         0             0                    0            0   \n",
       "2                         0             0                    0            1   \n",
       "5                         0             0                    0            1   \n",
       "6                         0             0                    0            0   \n",
       "8                         0             0                    0            0   \n",
       "\n",
       "        Style_Robust Porter  Style_Russian Imperial Stout  Style_Saison  \\\n",
       "BeerID                                                                    \n",
       "1                         0                             0             0   \n",
       "2                         0                             0             0   \n",
       "5                         0                             0             0   \n",
       "6                         0                             0             0   \n",
       "8                         0                             0             0   \n",
       "\n",
       "        Style_Sweet Stout  Style_Weissbier  Style_Weizen/Weissbier  \\\n",
       "BeerID                                                               \n",
       "1                       0                0                       0   \n",
       "2                       0                0                       0   \n",
       "5                       0                0                       0   \n",
       "6                       0                0                       0   \n",
       "8                       0                0                       0   \n",
       "\n",
       "        Style_Witbier  \n",
       "BeerID                 \n",
       "1                   0  \n",
       "2                   0  \n",
       "5                   0  \n",
       "6                   0  \n",
       "8                   0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc = (df\n",
    "       .drop(['PrimingMethod', 'PrimingAmount', 'UserId', 'PitchRate', 'PrimaryTemp', 'StyleID', 'Name', 'URL'], axis='columns')\n",
    "       .dropna(subset=['BoilGravity'])\n",
    "       .pipe(lambda df: df.join(pd.get_dummies(df['BrewMethod'], prefix='BrewMethod')))\n",
    "       .pipe(lambda df: df.join(pd.get_dummies(df['SugarScale'], prefix='SugarScale')))       \n",
    "       .pipe(lambda df: df.assign(Style=df['Style'].map(lambda s: s if s in popular_beer_styles else 'Other')))\n",
    "       .pipe(lambda df: df.join(pd.get_dummies(df['Style'], prefix='Style')))       \n",
    "       .drop(['BrewMethod', 'SugarScale', 'Style'], axis='columns')\n",
    "      )\n",
    "\n",
    "dfc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [c for c in dfc.columns if c != 'MashThickness']\n",
    "X = dfc[dfc['MashThickness'].notnull()].loc[:, c].values\n",
    "y = dfc[dfc['MashThickness'].notnull()]['MashThickness'].values\n",
    "yy = dfc[dfc['MashThickness'].isnull()]['MashThickness'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01557952331349366, 0.011168471985599338, 0.013375476821894994, 0.0045922744079380795, -0.0004321395799600225]\n",
      "('Average value of cross-validation results:', 0.00885672138979321)\n"
     ]
    }
   ],
   "source": [
    "# Apply a regression approach to imputing the mash thickness.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "kf = KFold(n_splits=5)\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    scores.append(r2_score(y_test, y_test_pred))\n",
    "\n",
    "print(scores)\n",
    "print('Average value of cross-validation results:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  *R2*  score measures how much better than baseline linear regression performs, where baseline is flat regression against the mean. In this case that baseline performance (an  R2  of 0) is the performance of replacing the missing values with the mean of the observed values. In this specific case the extremely low cross validation scores, all indistinguishable from 0, basically tells us that we've picked an impossible task: `MashThickness` cannot be determined with any accuracy from another of the other variables in the dataset (at least, if it can, then the relationship is non-linear—doubtful in this scenario). This cuts both ways, of course—if none of the variables in the dataset predict MashThickness, then MashThickness is useless for predicting anything any of them either!\n",
    "\n",
    "Nevertheless, for more usefully correlated columns this template of using a model of some kind to impute the column values is highly useful and makes a lot of sense from a practitioner's perspecive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3668100/) has the following to say about this technique (which it refers to as \"regression imputation\"; but, strictly speaking, it doesn't have to be regression):\n",
    "\n",
    "\n",
    "*This approach has a number of advantages, because the imputation retains a great deal of data over the listwise or pairwise deletion and avoids significantly altering the standard deviation or the shape of the distribution. However, as in a mean substitution, while a regression imputation substitutes a value that is predicted from other variables, no novel information is added, while the sample size has been increased and the standard error is reduced.*\n",
    "\n",
    "\n",
    "**In other words, this technique will still tend to increase the bias of the dataset, just less so (in success cases) than naively using the mean or median value would.**\n",
    "\n",
    "If you are looking for some other models to try, the fancyimpute package contains a number of (mostly matrix-based, e.g. linear algebraic) models specifically tuned for imputation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised learning\n",
    "\n",
    "You can use a set of techniques known as \"semi-supervised learning\" to attack missing data imputation. \n",
    "\n",
    "For some kinds of data you will run into the problem of having many samples, but not having labels for all of those samples, only for a subset of them. This situation occurs particularly often in research contexts, where it's often easy to get a small number of labelled data points, via hand-labelling, but significantly harder to gather the full dataset, if the full dataset is sufficiently large.\n",
    "\n",
    "This is known as the semi-supervised learning problem. It is semi-supervised because it lies in between unsupervised learning, which does not use labels, and supervised learning, which requires them. In a semi-supervised learning problem you don't have all the labels or none of them, only some of them.\n",
    "\n",
    "Semi-supervised learning is a restatement of the missing data imputation problem which is specific to the small-sample, missing-label case. This problem gets its own name likely because it is so commonly encountered in research and dataset generation contexts. It's a useful tool to know about more generally for missing data imputation from a limited sample size, but the algorithms have poor performance characteristics for larger samples. In those cases, perhaps try applying machine learning to the problem directly.\n",
    "\n",
    "To learn more about semi-supervised learning, check out the notebook \"Notes on semi-supervised learning\". The TLDR is that these techniques are an approach that works well when the number of labeled is extremely small, but do not scale to larger data because they involve building a similarity matrix, an  O(n2)  operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood imputation\n",
    "\n",
    "Simple approaches are easy to implement, but can lead to high bias. The model imputation approach is a bit more challenging, but it's still off-the-shelf, and it does still have a problem with introducing bias into the dataset. In fact, this paper (http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf) on the subject goes so far as to say that really you ought to be using either of two specialized techniques: maximum likelihood, or multiple imputation.\n",
    "\n",
    "In statistics the **maximum likelihood estimator** is any statistical estimator for a distribution of interest which has the property that it maximizes the \"likelihood function\" of that data.\n",
    "\n",
    "Recall that a statistical estimator takes a random sample of data and attempts to explain something about the overall distribution by generalizing from that sample. For example,  $ \\frac{∑(y)}{len(y)}$  is an estimator for the average of a set of data  y . It is MLE because it doesn't have any bias: it converges on the true mean of the distribution (given a large enough number of samples). For most problems an MLE estimator is the simplest estimator to build. But sometimes an MLE estimator is not possible, and in other cases some amount of bias in the estimator is useful (if you know something the model doesn't; see e.g. regularization).\n",
    "\n",
    "Maximum likelihood imputation is maximum likelihood estimation applied to missing data. First, **build a maximum likelihood estimator** with the complete records in the dataset as your predictor variables and the variable containing missing values your target. Then, for each record containing missing data, **draw a value from the distribution you generated**, one parameterized with the known dependent values of the data.\n",
    "\n",
    "This purely statistical approach to this problem has the drawback of statistical models more generally in that it is dependent on the probability distribution you use in your estimator. If you expect the data is normally distributed, you may fit a normal distribution to the data. If it's Bernoulli you can fit a Bernoulli distribution. If it's a combination of different distributions, then you have to build a multimodal distribution!\n",
    "\n",
    "For this reason there is no \"standard\" maximum likelihood estimator imputation technique. Instead, qouting from this excellent CrossValidated answer:\n",
    "\n",
    "Handling missing data with Maximum Likelihood on all available data (so-called FIML) is a very useful technique. However, there are a number of complications that make it challenging to implement in a general way.\n",
    "\n",
    "Consider a simple linear regression model, predicting some continuous outcome from say age, sex, and occupation type. In OLS, you do not worry about the distribution of age, sex, and occupation, only the outcome. Typically for categorical predictors, they are dummy coded (0/1). To use ML, distributional assumptions are required for all variables with missingness. By far the easiest approach is multivariate normal (MVN). This is what for example Mplus will do by default if you do not go out for your way to declare the type of variable (e.g., categorical).\n",
    "\n",
    "In the simple example I gave, you would probably want to assume, normal for age, Bernoulli for sex, and multinomal for job type. The latter is tricky because what you actually have are several binary variables, but you do not want to treat them as Bernoulli. This means you do not want to work with the dummy coded variables, you need to work with the actual categorical variable so the ML estimators can properly use a multinomial, but this in turn means that the dummy coding process needs to be built into the model, not the data. Again complicating life.\n",
    "\n",
    "Further, the joint distribution of continuous and categorical variables is nontrivial to compute (when I run into problems like this in Mplus, it pretty quickly starts to break down and struggle). Finally, you really ideally specify the missing data mechanism. In SEM style, FIML, all variables are essentially conditioned on all others, but this is not necessarily correct.\n",
    "\n",
    "For example, perhaps age is missing as a function not of gender and occupation type, but their interaction. The interaction may not be important for the focal outcome, but if it is important for missingness on age, then it must also be in the model, not necessarily the substantive model of interest but the missing data model.\n",
    "\n",
    "I don't know of any off-the-shelf maximum likelihood imputation algorithms in Python, for precisely this reason.\n",
    "\n",
    "The most flexible possible solution for modeling the distribution of data is kernel density estimation. sklearn includes *raw kernel density estimator algorithms* available. I might suggest starting there. Otherwise, if you want to go the statistical estimator route, the statsmodel package includes facilities for working with all of the most common types of statistical distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple imputation\n",
    "\n",
    "\n",
    "All of the techniques discussed so far are what one might call \"single imputation\": each value in the dataset is filled in exactly once. In general, the limitation with single imputation is that because these techniques find maximally likely values, they do not generate entries which accurately reflect the distribution of the underlying data.\n",
    "\n",
    "Take the extreme case of replacing missing values in the data with the mean value, for example. *If we had been able to observe the data we were missing, we would naturally expect to see some variability in it: extreme values, outliers, and records which do not completely fit the \"pattern\" of the data. This noise is intrinsic to the dataset, yet mean value replacement makes no attempt to represent it in its result. This leads to bias in any downstream models, which are exposed to a trend (the presence of the mean value in the datset) which does not exist in the underlying data. This in turn decreases accuracy during both the train and test phases.*\n",
    "\n",
    "In the statistical literature, arguably the most advanced methodology for performing missing data imputation is **multiple imputation**. In multiple imputation we generate missing values from the dataset many times. The individual datasets are then pooled together into the final imputed dataset, with the values chosen to replace the missing data being drawn from the combined results in some way. In other words, multiple imputation breaks imputation out into three steps: imputation (multiple times), analysis (staging how the results should be combined), and pooling (integrating the results into the final imputed matrix).\n",
    "\n",
    "Any technique that follows this general framework is a multiple imputation technique. As such, there are a variety of multiple imputation algorithms and implementations available. The most popular algorithm is called MICE, and a Python implementation thereof is available as part of the fancyimpute package: https://github.com/iskandr/fancyimpute.\n",
    "\n",
    "1) A simple imputation, such as imputing the mean, is performed for every missing value in the dataset. These mean imputations can be thought of as “place holders.”\n",
    "\n",
    "2) The “place holder” mean imputations for one variable (“var”) are set back to missing.\n",
    "\n",
    "3) The observed values from the variable “var” in Step 2 are regressed on the other variables in the imputation model, which may or may not consist of all of the variables in the dataset. In other words, “var” is the dependent variable in a regression model and all the other variables are independent variables in the regression model.\n",
    "\n",
    "4) The missing values for “var” are then replaced with predictions (imputations) from the regression model. When “var” is subsequently used as an independent variable in the regression models for other variables, both the observed and these imputed values will be used.\n",
    "\n",
    "5) Steps 2–4 are then repeated for each variable that has missing data. The cycling through each of the variables constitutes one iteration or “cycle.” At the end of one cycle all of the missing values have been replaced with predictions from regressions that reflect the relationships observed in the data.\n",
    "\n",
    "6) Steps 2 through 4 are repeated for a number of cycles, with the imputations being updated at each cycle. At the end of these cycles the final imputations are retained, resulting in one imputed dataset. Generally, ten cycles are performed; however, research is needed to identify the optimal number of cycles when imputing data under different conditions. The idea is that by the end of the cycles the distribution of the parameters governing the imputations (e.g., the coefficients in the regression models) should have converged in the sense of becoming stable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
